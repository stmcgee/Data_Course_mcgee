library(patchwork)
library(gganimate)
library(dplyr)
library(ggplot2)
library(ggplot2)
library("ggplot2", lib.loc="~/R/win-library/3.4")
library("gganimate", lib.loc="~/R/win-library/3.4")
library("tidyr", lib.loc="~/R/win-library/3.4")
library("patchwork", lib.loc="~/R/win-library/3.4")
library(tidyr)
library(ggplot2)
library(dplyr)
library(patchwork)
library(gganimate)
library("dbplyr", lib.loc="~/R/win-library/3.4")
detach("package:dbplyr", unload=TRUE)
library("dplyr", lib.loc="~/R/win-library/3.4")
library("ggplot2", lib.loc="~/R/win-library/3.4")
library("gganimate", lib.loc="~/R/win-library/3.4")
library("ggthemes", lib.loc="~/R/win-library/3.4")
library("patchwork", lib.loc="~/R/win-library/3.4")
library("tidyr", lib.loc="~/R/win-library/3.4")
Splot + geom_point(aes(col=region,)) + geom_smooth()
plot = ggplot(data = df, mapping = aes(x = Home.Value, y = Structure.Cost))
plot + geom_point()
# We can define different aesthetics within each geom we call (overwrites automatically if you define aesthetics that
# were defined globally in the ggplot() function)
plot + geom_point(aes(col=region))
ggplot(df, aes(x = Year, y = Home.Value)) + geom_smooth() + geom_point(aes(x=Year, y=Home.Value))
ggplot(MNESW) +
geom_point(aes(x=Year, y=Land.Value, col = State)) +
geom_smooth(aes(x=Year, y=Land.Value, col = State))
Splot + geom_point(aes(col=region,)) + geom_smooth(aes(x=Year, y=Land.Value, col=region))
Splot + geom_point(aes(col=region,)) + geom_smooth(aes(x=Year, y=Land.Value, col=region)) +
labs(x"Year",y="Cost of Land",title="Land Value over time per region")
Splot + geom_point(aes(col=region,)) + geom_smooth(aes(x=Year, y=Land.Value, col=region)) +
labs(x="Year",y="Cost of Land",title="Land Value over time per region")
Fplot = Splot + geom_point(aes(col=region,)) + geom_smooth(aes(x=Year, y=Land.Value, col=region)) +
labs(x="Year",y="Cost of Land",title="Land Value over time per region")
Fplot + theme_economist()
Fplot + theme_fivethirtyeight()
dada2::
library(dada2)
source('~/.active-rstudio-document', echo=TRUE)
mod1 = aov(GrowthRate ~ Species + Light + Humidity + Temperature + Nitrogen, data = df)
summary(mod1)
mod2 = aov(GrowthRate ~ Species*Light*Humidity*Temperature*Nitrogen, data = df)
summary(mod2)
library(gapminder)
install.packages("gapminder")
library(gapminder)
df = gapminder
glimpse(df)
source('~/.active-rstudio-document', echo=TRUE)
df = read.csv("c:/Users/spencer/Desktop/Data_Course/Data_Course/data/BioLog_Plate_Data.csv")
df = read.csv("c:/Users/spencer/Desktop/Data_Course/Data_Course/data/BioLog_Plate_Data.csv")
View(df)
sub1 = subset(df, Substrate == "D-Cellobiose")
ggplot(df , aes(x=))
gather(sub1, key = "Time", value = "Abs",)
?gather
gather(sub1, key = "Time", value = "Abs", c("Hr_24","Hr_48","Hr_144"))
Sub1_Long = gather(sub1, key = "Time", value = "Abs", c("Hr_24","Hr_48","Hr_144"))
ggplot(Sub1_Long, aes(x="Time",y="Abs")) +
geom_point()
ggplot(Sub1_Long, aes(x=Time,y=Abs, col=Sample.ID)) +
geom_point()
ggplot(Sub1_Long, aes(x=Time,y=Abs, col=Sample.ID)) +
geom_point() +
geom_smooth()
library(plyr)
library(plyr)
library(plyr)
library(ggplot2)
library(dplyr)
library(tidyr)
?mapvalues
mapvalues(Sub1_Long, c("Hr_24","Hr_48","Hr_144", c("24","48","144")))
mapvalues(Sub1_Long, c("Hr_24","Hr_48","Hr_144"), c("24","48","144")))
mapvalues(Sub1_Long$Time, c("Hr_24","Hr_48","Hr_144"), c("24","48","144")))
mapvalues(Sub1_Long$Time, from = c("Hr_24","Hr_48","Hr_144"), to = c("24","48","144")))
mapvalues(Sub1_Long$Time, from = c("Hr_24","Hr_48","Hr_144"), to = c("24","48","144"))
Sub1_long$time = as.numeric(mapvalues(Sub1_Long$Time, from = c("Hr_24","Hr_48","Hr_144"), to = c("24","48","144")))
Sub1_Long$time = as.numeric(mapvalues(Sub1_Long$Time, from = c("Hr_24","Hr_48","Hr_144"), to = c("24","48","144")))
ggplot(Sub1_Long, aes(x=Time,y=Abs, col=Sample.ID)) +
geom_point() +
geom_smooth()
Sub1_Long$time = as.numeric(mapvalues(Sub1_Long$Time, from = c("Hr_24","Hr_48","Hr_144"), to = c(24,48,144)))
ggplot(Sub1_Long, aes(x=Time,y=Abs, col=Sample.ID)) +
geom_point() +
geom_smooth()
mapvalues(Sub1_Long$Time, from = c("Hr_24","Hr_48","Hr_144"), to = c(24,48,144))
df = read.csv("c:/Users/spencer/Desktop/Data_Course/Data_Course/data/BioLog_Plate_Data.csv")
sub1 = subset(df, Substrate == "D-Cellobiose")
Sub1_Long = gather(sub1, key = "Time", value = "Abs", c("Hr_24","Hr_48","Hr_144"))
mapvalues(Sub1_Long$Time, from = c("Hr_24","Hr_48","Hr_144"), to = c(24,48,144))
Sub1_Long$Time = as.numeric(mapvalues(Sub1_Long$Time, from = c("Hr_24","Hr_48","Hr_144"), to = c(24,48,144)))
ggplot(Sub1_Long, aes(x=Time,y=Abs, col=Sample.ID)) +
geom_point() +
geom_smooth()
View(df)
df_Long = gather(df, key = "Time", value = "Abs", c("Hr_24","Hr_48","Hr_144"))
df_Long$Time = as.numeric(mapvalues(df_Long$Time, from = c("Hr_24","Hr_48","Hr_144"), to = c(24,48,144)))
ggplot2::
autoplot(df_Long$Substrate, aes(x=Time,y=Abs, col=Sample.ID))
d1 = read.csv("/Users/spencer/Desktop/Data_Course/Data_Course/data/mushroom_growth.csv")
for (i in names(d1)){
plot(df[,"GrowthRate"] ~ df[,i], xlab = "GrowthRate", ylab = i, main = i)
}
sustrates = levels(df_Long$Substrate)
for (i in levels(df_Long$Substrate)) {
sub = subset(df_Long, Subtrate == i), ggplot(sub, aes(x=Time,y=Abs, col=Sample.ID)) +
geom_point() +
stat_smooth()
}
substrates = levels(df_Long$Substrate)
plot.substrate = function(x){
ggplot(df_Long[df_Long$Substrate == x,],aes(x=Time,y=Abs,col=Sample.ID)) + geom_point() + geom_smooth(se=FALSE) + ggtitle(x)
}
lapply(substrates, plot.substrate)
library(tidy)
source('~/.active-rstudio-document', echo=TRUE)
library(tidyr)
x = rnorm(10)
y = rnorm(10)
z = rnorm(10)
obs = 1:10
df = data.frame(obs = obs,
X=x
y=y
z=z)
df = data.frame(obs = obs,
X=x,
y=y,
z=z)
df.l = gather(df, key = "Stock", Valure = "PriceChage", c("x","y","z"))
df.l = gather(df, key = "Stock", Value = "PriceChage", c("x","y","z"))
df.1 = gather(df, key = "Stock", value = "PriceChage", c("x","y","z"))
df.1 = gather(df, key = "Stock", value = "PriceChage", c("X","y","z"))
View(df.1)
spread(df.1, Stock, PriceChange)
spread(df.1, Stock, PriceChage)
df.1
aov(PriceChage ~ Stock*obs, data = df.1)
library(dplyr)
?mapvalues
df.1
spread(df.1, Stock, PriceChage)
dplyr::
df %>% mutate(total = x+y+z)
dplyr::
df %>% mutate(total = x+y+z, max(x,y,z))
dplyr::
df %>% mutate(total = x+y+z, max = max(x,y,z))
df2 = read.csv("../Data_Course/data/iris.csv")
plot(df2)
mod1 = aov(Petal.Length ~Petal.Width*Species, data = df2)
summary(mod1)
mod1 = aov(Petal.Length ~ Petal.Width*Species, data = df2)
summary(mod1)
mod2 = aov(Petal.Length ~ Petal.Width+Species, data = df2)
summary(mod2)
anova(mod1,mod2)
library(ggplot2)
ggplot(df2) +
geom_point(aes(x=Petal.Width, y=Petal.Length, color=species))
ggplot(df2) +
geom_point(aes(x=Petal.Width,y=Petal.Length, color=species))
ggplot(df2) +
geom_point(aes(x=Petal.Width,y=Petal.Length, color=Species))
# which one is better?
library(modelr)
add_predictions(df2,mod1,var = mod1)
mod1 = lm(Petal.Length ~ Petal.Width*Species, data = df2)
mod2 = lm(Petal.Length ~ Petal.Width+Species, data = df2)
add_predictions(df2,mod1,var = mod1)
add_predictions(df2,mod1,var = mod1)
mod1 = aov(Petal.Length ~ Petal.Width*Species, data = df2)
mod2 = aov(Petal.Length ~ Petal.Width+Species, data = df2)
add_predictions(df2,"mod1",var = mod1)
add_predictions(df2,mod1,var = "mod1")
df2 = add_predictions(df2,mod1,var = "mod1")
df2 = add_predictions(df2,mod2,var = "mod2")
add_predictions(df2,mod2,var = "mod2")
ggplot(df2) +
geom_point(aes(x=Petal.Width,y=Petal.Length, color=Species))
ggplot(df2) +
geom_point(aes(x=Petal.Width,y=Petal.Length, color=Species)) +
geom_smooth(aes(x=Petal.Width,y=mod1),col="Blue",method = "lm")
ggplot(df2) +
geom_point(aes(x=Petal.Width,y=Petal.Length, color=Species)) +
geom_smooth(aes(x=Petal.Width,y=mod1),col="Blue",method = "lm") +
geom_smooth(aes(x=Petal.Width,y=mod2),col="Red",method = "lm")
ggplot(df2) +
geom_point(aes(x=Petal.Width,y=Petal.Length, color=Species)) +
geom_smooth(aes(x=Petal.Width,y=mod1,col=Species),method = "lm",linetype=8) +
geom_smooth(aes(x=Petal.Width,y=mod2,col=Species),method = "lm",linetype=5)
ggplot(df2) +
geom_point(aes(x=Petal.Width,y=Petal.Length, color=Species)) +
geom_smooth(aes(x=Petal.Width,y=mod1,col=Species),method = "lm") +
geom_smooth(aes(x=Petal.Width,y=mod2,col=Species),method = "lm",linetype=5)
(df2$mod1 - df2$Petal.Length)^2
sqrt(mean((df2$mod2 - df2$Petal.Length)^2))
sqrt(mean((df2$mod1 - df2$Petal.Length)^2))
library(dada2)
?fnFs
path <- "c:/Users/spencer/Desktop/Data_Course/Data_Course_mcgee/Final_Project/SpencerMcGee_Seqs_and_Metadata/"
list.files(path)
setwd(path)
read.csv("Snail_MetaData.csv")
snmeta = read.csv("Snail_MetaData.csv")
snmeta = read.csv("Snail_MetaData.csv")
?Save
source('~/.active-rstudio-document', echo=TRUE)
rm(list = ls())
# Load the libraries that you use here:
library(plyr)
library(ggplot2)
library(dplyr)
library(tidyr)
# read in salaries.csv
df = read.csv("c:/Users/spencer/Desktop/Data_Course/Data_Course/exam2/salaries.csv")
# convert to usable format so we can look at salaries as a dependent variable (10 points)
glimpse(df)
list(df)
plot(df)
df.1 = gather(df, key = "Salaries", value = "Position", c("AssistProf","AssocProf","FullProf"))
list(df.1)
df.1 = gather(df, key = "Position", value = "Salaries", c("AssistProf","AssocProf","FullProf"))
glimpse(df.1)
df.1 = gather(df, key = "Facilityrank", value = "Salaries", c("AssistProf","AssocProf","FullProf"))
glimpse(df.1)
df.1 = gather(df, key = "Rank", value = "Salaries", c("AssistProf","AssocProf","FullProf"))
plot1 = ggplot(df.1, aes(x=Tier, y=Salaries, col="Rank")) +
geom_point()
ggplot(df.1, aes(x=Tier, y=Salaries, col="Rank")) +
geom_point()
df.1 = gather(df, key = "Rank", value = "Salaries", c(AssistProf,AssocProf,FullProf))
glimpse(df.1)
?as.factor()
ggplot(df.1, aes(x=Tier, y=Salaries) col="Rank") +
geom_boxplot()
ggplot(df.1, aes(x=Tier, y=Salaries), col="Rank") +
geom_boxplot()
ggplot(df.1, aes(x=Tier, y=Salaries)) +
geom_boxplot(fill = Rank)
ggplot(df.1, aes(x=Tier, y=Salaries)) +
geom_boxplot(fill = "Rank")
df.1$Rank = as.factor(mapvalues(df.1$Rank, from = c(AssistProf,AssocProf,FullProf), to = c("Assist","Assoc","Full")))
df.1 = gather(df, key = "Rank", value = "Salaries", c("AssistProf","AssocProf","FullProf"))
df.1$Rank = as.factor(mapvalues(df.1$Rank, from = c(AssistProf,AssocProf,FullProf), to = c("Assist","Assoc","Full")))
glimpse(df.1)
df.1$Rank = as.factor(mapvalues(df.1$Rank, from = c("AssistProf","AssocProf","FullProf"), to = c("Assist","Assoc","Full")))
glimpse(df.1)
ggplot(df.1, aes(x=Tier, y=Salaries)) +
geom_boxplot(fill = "Rank")
ggplot(df.1, aes(x=Tier, y=Salaries)) +
geom_boxplot(fill = df.1$Rank)
ggplot(df.1, aes(x=Tier, y=Salaries)) +
geom_boxplot(fill = "blue")
ggplot(df.1, aes(x=Tier, y=Salaries)) +
geom_boxplot(fill = Rank)
ggplot(df.1, aes(x=Tier, y=Salaries)) +
geom_boxplot(fill = "Rank")
ggplot(df.1, aes(x=Tier, y=Salaries)) +
geom_boxplot() fill="Rank"
ggplot(df.1, aes(x=Tier, y=Salaries) title(main="Faculty Salaries - 1995")) +
geom_boxplot()
ggplot(df.1, aes(x=Tier, y=Salaries)) title(main="Faculty Salaries - 1995") +
geom_boxplot()
ggplot(df.1, aes(x=Tier, y=Salaries)) +
title(main="Faculty Salaries - 1995") +
geom_boxplot()
ggplot(df.1, aes(x=Tier, y=Salaries), title(main = "Faculty Salaries - 1995")) +
geom_boxplot()
ggplot(df.1, aes(x=Tier, y=Salaries), main = "Faculty Salaries - 1995") +
geom_boxplot()
df2 = read.csv("c:/Users/spencer/Desktop/Data_Course/Data_Course/exam2/atmosphere.csv")
norm(df2)
plot(df2)
mod1 = aov(Diversity ~ CO2+Aerosols, data = df2)
glimpse(df2)
mod1 = aov(Diversity ~ CO2_Concentration+Aerosol_Density, data = df2)
summary(mod1)
ggplot(df.1, aes(x=Tier, y=Salaries, fill=Rank)) +
geom_boxplot() +
ggtitle("Faculty Salaries - 1995")
setwd("c:/Users/spencer/Desktop/Data_Course/Data_Course_mcgee/")
save.image("Mcgee_exam2_plot1.jpeg")
glimpse(df2)
df2$Year <- factor(df2$Year)
glimpse(df2)
mod1 = lm(Diversity ~ CO2_Concentration+Aerosol_Density, data = df2)
plot(mod1)
df2$Year <- factor(df2$Year)
mod2 = aov(Diversity ~ Year, data = df2)
summary(mod2)
mod3 = aov(Diversity ~ Year*Aerosol_Density, data = df2)
anova(mod2,mod3)
test1 = anova(mod2,mod3)
write.table(test1, "Mcgee_exam2_table1.txt", sep=",")
library(modelr)
?add_predictions
mod1 = aov(Diversity ~ Day+SampleID+Year+Quarter+Month+Mday+BarcodeSequence+CO2_Concentration+Aerosol_Density, data = df2)
mod1 = aov(Diversity ~ CO2_Concentration+Aerosol_Density, data = df2)
add_predictors
mod1 = aov(Diversity ~ Year+Quarter+Month+Mday+BarcodeSequence+CO2_Concentration+Aerosol_Density, data = df2)
?obs
??obs
ndf = (Year=Year,Quarter=Quarter,Month=Month,Mday=Mday,BarcodeSequence=BarcodeSequence,Aerosol_Density=Aerosol_DensityCO2_Concentration=CO2_Concentration)
ndf = (Year=Year, Quarter=Quarter, Month=Month, Mday=Mday, BarcodeSequence=BarcodeSequence, Aerosol_Density=Aerosol_Density, CO2_Concentration=CO2_Concentration)
# Year = 2007
# Quarter = "Q4"
# Month = August
# Mday = 10
# BarcodeSequence = "CTCTCTATCAGTGAGT"
# Aerosol_Density = 1000,
# CO2_Concentration = 384
ndf=[Year = 2007, Quarter = "Q4", Month = August, Mday = 10, BarcodeSequence = "CTCTCTATCAGTGAGT", Aerosol_Density = 1000, CO2_Concentration = 384]
# Year = 2007
# Quarter = "Q4"
# Month = August
# Mday = 10
# BarcodeSequence = "CTCTCTATCAGTGAGT"
# Aerosol_Density = 1000,
# CO2_Concentration = 384
ndf = [Year = 2007, Quarter = "Q4", Month = August, Mday = 10, BarcodeSequence = "CTCTCTATCAGTGAGT", Aerosol_Density = 1000, CO2_Concentration = 384]
View(mod2)
df2.p = add_predictions(df2,mod1, var = "Year" = 2007 , "Quarter" = Q4, "Month" = August, "Mday" = 10, "BarcodeSequence" = "CTCTCTATCAGTGAGT", "Aerosol_Density" = 1000, "CO2_Concentration" = 384)
df2.p = add_predictions(df2,mod1, var = "mod1")
View(df2.p)
source("http://bioconductor.org/biocLite.R")
biocLite()
a
a
a
a
a
source("http://bioconductor.org/biocLite.R")
biocLite()
a
a
a
a
a
a
a
a
a
library(ShortRead)
library(tidyr)
library(stringr)
library(msa)
library(seqinr)
library(tidyr)
library(seqinr)
source("http://bioconductor.org/biocLite.R")
biocLite(c("DESeq","topGO"))
# Load the vegan package
library(vegan)
# Install vegan, if you haven't already
install.packages("vegan")
install.packages("vegan")
# Load the vegan package
library(vegan)
# Set random seed so results are reproducible
set.seed(55)
# Generate a random community matrix, similar to the type of data in an OTU Table
prob = c(0.99,rep(0.05,1000)) # sets probability of each number being randomly chosen
community_matrix=matrix(
sample(0:1000,300,replace=T, prob = prob),nrow=10,
dimnames=list(paste("Sample_",1:10,sep=""),paste("OTU_",1:30,sep="")))
# Add a treatment vector, assigning samples to one of two groups
treat=c(rep("Treatment_1",5),rep("Treatment_2",5))
# Take a quick look at your "OTU Table"
community_matrix  # should have 10 samples as rows, and 30 OTUs as columns
# Check to see how even your sampling effort for each community is
barchart(rowSums(community_matrix))
min_depth = min(rowSums(community_matrix)) # this gives us the minimum number of reads in a given sample
# Look at rarefaction (species accumulation) curve
rarecurve(community_matrix, step = 100, sample = min_depth) # vegan's built-in S.A.C. function
# We should normalize our data to account for variable sequencing depth.  One way is to rarefy...
set.seed(55) # set random seed so it's reproducible
rare_community_matrix = rrarefy(community_matrix, min_depth) # randomly subsamples data to given depth and makes new OTU table
# How many species were found in each sample?
specnumber(community_matrix)
specnumber(rare_community_matrix)
# How many species were found in each treatment group?
specnumber(community_matrix, groups = treat)
specnumber(rare_community_matrix, groups = treat)
# Calculate Shannon diversity for each sample
diversity(community_matrix, index = "shannon")
?diversity
# Calculate Shannon diversity for each sample
div1 = diversity(community_matrix, index = "shannon")
div2 = diversity(rare_community_matrix, index = "shannon")
plot(div1,div2)
# Beta diversity (basic Whittaker index)
beta_div = betadiver(community_matrix, method = "w")
beta_disp = betadisper(beta_div, treat)
plot(beta_disp)
beta_div
beta_div
beta_div
example_NMDS = metaMDS(rare_community_matrix, # Our community-by-species matrix
k=2) # The number of reduced dimensions
stressplot(example_NMDS) # Lots of scatter means poor preservation
# Plot the ordination
ordiplot(example_NMDS, type = "n") # Sets up the plotting area
orditorp(example_NMDS,display="sites",col="red",air=0.01) # Adds the samples in ordination space
ordiellipse(example_NMDS, groups = treat, label = TRUE) # Calculates the centroid and 95% C.I. of each treatment group
# To read a tsv file into R we can do the following:
otu_table = read.delim("~/Desktop/Data_Course/Data_Course/code_examples/Vegan_Example/vegan_example_otu_table.tsv", sep = "\t", row.names = 1)
# To read a tsv file into R we can do the following:
otu_table = read.delim("C:/Desktop/Data_Course/Data_Course/code_examples/Vegan_Example/vegan_example_otu_table.tsv", sep = "\t", row.names = 1)
# To read a tsv file into R we can do the following:
otu_table = read.delim("c:/Users/spencer/Desktop/Data_Course/Data_Course/code_examples/Vegan_Example/vegan_example_otu_table.tsv", sep = "\t", row.names = 1)
metadata = read.delim("c:/Users/spencer/Desktop/Data_Course/Data_Course/code_examples/Vegan_Example/vegan_example_metadata.tsv", sep = "\t", row.names = 1)
View(metadata)
dim(otu_table)
dim(metadata)
View(otu_table)
# Look at the names of the columns in the OTU table (sample names)
names(otu_table) # that last one is the taxonomy from QIIME
# We can build a separate data frame to store our taxonomic assignments
Taxonomy = data.frame(Taxonomy = otu_table$Tax_Name, row.names = rownames(otu_table))
# And now, get rid of them from the otu table for now so we can use vegan
otu_table = otu_table[,which(colnames(otu_table) != "Tax_Name")]
# Now, transpose the otu table so rows are samples, and OTUs are columns
otu_table = as.data.frame(t(otu_table))
# Now, let's check the dimensions again
dim(otu_table)
dim(metadata)
# ...And make sure they're in the right order
identical(rownames(otu_table), rownames(metadata)) # if "TRUE", then they are exactly the same, and in the same order
# Just like the example with random data, we will first take a look at sampling effort
barchart(rowSums(otu_table))
# What is the minimum number of reads in a given sample?
min_depth2 = min(rowSums(otu_table)) # should be 2000 for this data set
# Look at rarefaction curves and draw vertical line at the minimum depth (our probable rarefication level)
rarecurve(otu_table, sample = 2000, step = 100, cex = .5)
# Normalize the data by rarefying
set.seed(1)
rare_otu_table = rrarefy(otu_table, min_depth2)
# How many OTUs are found in each sample?
specnumber(otu_table)
specnumber(rare_otu_table)
# compare before and after rarefication
plot(specnumber(otu_table),specnumber(rare_otu_table)) # there was some loss of species richness during rarification
# Look at it by groups (Ecosystem)
specnumber(otu_table, groups = metadata$Ecosystem) # refers to the metadata table
specnumber(rare_otu_table, groups = metadata$Ecosystem) # refers to the metadata table
# Look at Shannon Diversity
diversity(otu_table, "shannon")
diversity(rare_otu_table, "shannon")
# compare before and after rarefication
plot(diversity(otu_table, "shannon"),
diversity(rare_otu_table, "shannon"))
# Find the number of samples in which each OTU is found
species_presence = apply(rare_otu_table > 0,2,sum)
barchart(species_presence)
# We can have some help deciding which distance index to use (Bray-Curtis is the default)
rank_otus = rankindex(metadata$Ecosystem, rare_otu_table, indices =
c("bray", "euclid", "manhattan", "horn"), method = "spearman")
print(paste("The highest rank was given by the", names(sort(rank_otus, decreasing = TRUE)[1]), "method."))
rank_otus
# run NMDS (this calculates the distance using "horn" method, transforms the data, and runs isoMDS 20 times to find best
# solution)
MDS = metaMDS(rare_otu_table, distance = "bray", try = 50, trymax = 100)
# Check out the stress plot
stressplot(MDS)  # looks pretty good - has linear fit R2 of 0.946
# Plot it
ordiplot(MDS, type = "p")
ordiellipse(MDS, groups = metadata$Ecosystem, label = TRUE) # Calculates the centroid and 95% C.I. of each treatment group
rare_otu_table.horn = vegdist(rare_otu_table, method = "horn") # Generates the distance matrix, as in metaMDS
beta_div = betadisper(rare_otu_table.horn, group = metadata$Ecosystem) # Calculate homogeneity of multivariate dispersions
boxplot(beta_div) # show boxplot of beta diversity by ecosystem
# We call pull out the cartesian coordinates and build a data frame that is easier to work with
MDS1 = MDS$points[,1] # gives vector of X coordinates
MDS2 = MDS$points[,2] # gives vector of Y coordinates
NMDS = data.frame(MDS1 = MDS1, MDS2 = MDS2, Ecosystem = metadata$Ecosystem,
Lat = metadata$Latitude, Lon = metadata$Longitude, Host = metadata$Host)
# Load ggplot2, a package that allows much more flexible visualization of data
library(ggplot2)
# ggplot2 is its own can of worms, but it can label, color, and make a legend automatically, which is nice
ggplot(NMDS, mapping = aes(x = MDS1, y = MDS2, col = Ecosystem)) +
geom_point() +
stat_ellipse() +
theme_bw() +
ggtitle("NMDS")
# Load ggplot2, a package that allows much more flexible visualization of data
library(ggplot2)
library("ggplot2", lib.loc="~/R/win-library/3.4")
# ggplot2 is its own can of worms, but it can label, color, and make a legend automatically, which is nice
ggplot(NMDS, mapping = aes(x = MDS1, y = MDS2, col = Ecosystem)) +
geom_point() +
stat_ellipse() +
theme_bw() +
ggtitle("NMDS")
# Load ggplot2, a package that allows much more flexible visualization of data
library(ggplot2)
install.packages(c("lubridate", "stringdist"))
# Load ggplot2, a package that allows much more flexible visualization of data
library(ggplot2)
# ggplot2 is its own can of worms, but it can label, color, and make a legend automatically, which is nice
ggplot(NMDS, mapping = aes(x = MDS1, y = MDS2, col = Ecosystem)) +
geom_point() +
stat_ellipse() +
theme_bw() +
ggtitle("NMDS")
#try using adonis()
?adonis
